{
    "dims": {
        "input": 10,
        "output": 3,
        "output_after_transform": 3
    },
    "loss": {
        "otype": "RelativeL2Luminance",
        "luminance_weighting": false,
        "custom_weighting": false,
        "tonemapped": false,
        "lum_weight": 1.0,
        "var_weight": 0.0,
        "luminance_divider": 0.01
    },
    "optimizer": {
        "otype": "EMA",
        "nested": {
            "otype": "Adam",
            "learning_rate": 0.001,
            "beta1": 0.9,
            "beta2": 0.99,
            "l2_reg": 0.00000001,
            "epsilon": 0.0000000000000001
        }
    },
    "encoding": {
        "otype": "Composite",
        "nested": [
            {
                "n_dims_to_encode": 2,
                "otype": "OneBlob",
                "n_bins": 4,
                "packed": true
            },
            {
                "n_dims_to_encode": 3,
                "otype": "HashGrid",
                "n_levels": 12,
                "log2_hashmap_size": 19,
                "n_features_per_level": 2,
                "weight_masking": false,
                "atten_steps": [0, 0, 0, 200, 200, 200, 200, 200, 400, 400, 0, 0, 0, 0]
            },
            {
                "n_dims_to_encode": 1,
                "otype": "OneBlob",
                "n_bins": 4
            },
            {
                "n_dims_to_encode": 3,
                "otype": "Identity"
            },
            {
                "n_dims_to_encode": 1,
                "otype": "SphericalHarmonics",
                "degree": 5,
                "packed": true,
                "move_forward": true,
                "weight_masking": false
            }
        ]
    },
    "network": {
        "otype": "FullyFusedMLP",
        "n_neurons": 64,
        "n_hidden_layers": 4,
        "activation": "ReLU",
        "output_activation": "None"
    }
}
